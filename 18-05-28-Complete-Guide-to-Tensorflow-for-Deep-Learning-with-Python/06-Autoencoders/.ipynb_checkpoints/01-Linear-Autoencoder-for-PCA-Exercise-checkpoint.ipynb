{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder for PCA - EXERCISE \n",
    "\n",
    "** Follow the bold instructions below to reduce a 30 dimensional data set for classification into a 2-dimensional dataset! Then use the color classes to see if you still kept the same level of class separation in the dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "** Import numpy, matplotlib, and pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use pandas to read in the csv file called anonymized_data.csv . It contains 500 rows and 30 columns of anonymized data along with 1 last column with a classification label, where the columns have been renamed to 4 letter codes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/anonymized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.032145</td>\n",
       "      <td>1.019576</td>\n",
       "      <td>-9.658715</td>\n",
       "      <td>-6.210495</td>\n",
       "      <td>3.156823</td>\n",
       "      <td>7.457850</td>\n",
       "      <td>-5.313357</td>\n",
       "      <td>8.508296</td>\n",
       "      <td>3.959194</td>\n",
       "      <td>-5.246654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.209663</td>\n",
       "      <td>-10.340123</td>\n",
       "      <td>-7.697555</td>\n",
       "      <td>-5.932752</td>\n",
       "      <td>10.872688</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>1.276316</td>\n",
       "      <td>5.281225</td>\n",
       "      <td>-0.516447</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.306217</td>\n",
       "      <td>6.649376</td>\n",
       "      <td>-0.960333</td>\n",
       "      <td>-4.094799</td>\n",
       "      <td>8.738965</td>\n",
       "      <td>-3.458797</td>\n",
       "      <td>7.016800</td>\n",
       "      <td>6.692765</td>\n",
       "      <td>0.898264</td>\n",
       "      <td>9.337643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851793</td>\n",
       "      <td>-9.678324</td>\n",
       "      <td>-6.071795</td>\n",
       "      <td>1.428194</td>\n",
       "      <td>-8.082792</td>\n",
       "      <td>-0.557089</td>\n",
       "      <td>-7.817282</td>\n",
       "      <td>-8.686722</td>\n",
       "      <td>-6.953100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.570842</td>\n",
       "      <td>6.985462</td>\n",
       "      <td>-1.842621</td>\n",
       "      <td>-1.569599</td>\n",
       "      <td>10.039339</td>\n",
       "      <td>-3.623026</td>\n",
       "      <td>8.957619</td>\n",
       "      <td>7.577283</td>\n",
       "      <td>1.541255</td>\n",
       "      <td>7.161509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376085</td>\n",
       "      <td>-8.971164</td>\n",
       "      <td>-5.302191</td>\n",
       "      <td>2.898965</td>\n",
       "      <td>-8.746597</td>\n",
       "      <td>-0.520888</td>\n",
       "      <td>-7.350999</td>\n",
       "      <td>-8.925501</td>\n",
       "      <td>-7.051179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.139972</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>-9.526530</td>\n",
       "      <td>-5.744928</td>\n",
       "      <td>4.834355</td>\n",
       "      <td>5.907235</td>\n",
       "      <td>-4.804137</td>\n",
       "      <td>6.798810</td>\n",
       "      <td>5.403670</td>\n",
       "      <td>-7.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270571</td>\n",
       "      <td>-8.640988</td>\n",
       "      <td>-8.105419</td>\n",
       "      <td>-5.079015</td>\n",
       "      <td>9.351282</td>\n",
       "      <td>0.641759</td>\n",
       "      <td>1.898083</td>\n",
       "      <td>3.904671</td>\n",
       "      <td>1.453499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.738104</td>\n",
       "      <td>0.234729</td>\n",
       "      <td>-11.558768</td>\n",
       "      <td>-7.181332</td>\n",
       "      <td>4.189626</td>\n",
       "      <td>7.765274</td>\n",
       "      <td>-2.189083</td>\n",
       "      <td>7.239925</td>\n",
       "      <td>3.135602</td>\n",
       "      <td>-6.211390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>-9.437110</td>\n",
       "      <td>-6.475267</td>\n",
       "      <td>-5.708377</td>\n",
       "      <td>9.623080</td>\n",
       "      <td>1.802899</td>\n",
       "      <td>1.903705</td>\n",
       "      <td>4.188442</td>\n",
       "      <td>1.522362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EJWY      VALM       EGXO      HTGR       SKRF      NNSZ      NYLC  \\\n",
       "0 -2.032145  1.019576  -9.658715 -6.210495   3.156823  7.457850 -5.313357   \n",
       "1  8.306217  6.649376  -0.960333 -4.094799   8.738965 -3.458797  7.016800   \n",
       "2  6.570842  6.985462  -1.842621 -1.569599  10.039339 -3.623026  8.957619   \n",
       "3 -1.139972  0.579422  -9.526530 -5.744928   4.834355  5.907235 -4.804137   \n",
       "4 -1.738104  0.234729 -11.558768 -7.181332   4.189626  7.765274 -2.189083   \n",
       "\n",
       "       GWID      TVUT      CJHI  ...        LKKS       UOBF      VBHE  \\\n",
       "0  8.508296  3.959194 -5.246654  ...   -2.209663 -10.340123 -7.697555   \n",
       "1  6.692765  0.898264  9.337643  ...    0.851793  -9.678324 -6.071795   \n",
       "2  7.577283  1.541255  7.161509  ...    1.376085  -8.971164 -5.302191   \n",
       "3  6.798810  5.403670 -7.642857  ...    0.270571  -8.640988 -8.105419   \n",
       "4  7.239925  3.135602 -6.211390  ...   -0.013973  -9.437110 -6.475267   \n",
       "\n",
       "       FRWU       NDYZ      QSBO      JDUB      TEVK      EZTM  Label  \n",
       "0 -5.932752  10.872688  0.081321  1.276316  5.281225 -0.516447    0.0  \n",
       "1  1.428194  -8.082792 -0.557089 -7.817282 -8.686722 -6.953100    1.0  \n",
       "2  2.898965  -8.746597 -0.520888 -7.350999 -8.925501 -7.051179    1.0  \n",
       "3 -5.079015   9.351282  0.641759  1.898083  3.904671  1.453499    0.0  \n",
       "4 -5.708377   9.623080  1.802899  1.903705  4.188442  1.522362    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 31 columns):\n",
      "EJWY     500 non-null float64\n",
      "VALM     500 non-null float64\n",
      "EGXO     500 non-null float64\n",
      "HTGR     500 non-null float64\n",
      "SKRF     500 non-null float64\n",
      "NNSZ     500 non-null float64\n",
      "NYLC     500 non-null float64\n",
      "GWID     500 non-null float64\n",
      "TVUT     500 non-null float64\n",
      "CJHI     500 non-null float64\n",
      "NVFW     500 non-null float64\n",
      "VLBG     500 non-null float64\n",
      "IDIX     500 non-null float64\n",
      "UVHN     500 non-null float64\n",
      "IWOT     500 non-null float64\n",
      "LEMB     500 non-null float64\n",
      "QMYY     500 non-null float64\n",
      "XDGR     500 non-null float64\n",
      "ODZS     500 non-null float64\n",
      "LNJS     500 non-null float64\n",
      "WDRT     500 non-null float64\n",
      "LKKS     500 non-null float64\n",
      "UOBF     500 non-null float64\n",
      "VBHE     500 non-null float64\n",
      "FRWU     500 non-null float64\n",
      "NDYZ     500 non-null float64\n",
      "QSBO     500 non-null float64\n",
      "JDUB     500 non-null float64\n",
      "TEVK     500 non-null float64\n",
      "EZTM     500 non-null float64\n",
      "Label    500 non-null float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 121.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.237752</td>\n",
       "      <td>3.755108</td>\n",
       "      <td>-5.614445</td>\n",
       "      <td>-4.747200</td>\n",
       "      <td>6.447995</td>\n",
       "      <td>1.776850</td>\n",
       "      <td>1.718450</td>\n",
       "      <td>7.208016</td>\n",
       "      <td>2.556548</td>\n",
       "      <td>1.222064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295252</td>\n",
       "      <td>-9.053808</td>\n",
       "      <td>-6.291877</td>\n",
       "      <td>-2.345864</td>\n",
       "      <td>1.125596</td>\n",
       "      <td>0.284048</td>\n",
       "      <td>-2.817147</td>\n",
       "      <td>-2.192278</td>\n",
       "      <td>-2.816977</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.121210</td>\n",
       "      <td>2.540833</td>\n",
       "      <td>3.853295</td>\n",
       "      <td>2.164355</td>\n",
       "      <td>2.796104</td>\n",
       "      <td>5.030617</td>\n",
       "      <td>5.771508</td>\n",
       "      <td>1.167246</td>\n",
       "      <td>2.146874</td>\n",
       "      <td>7.410762</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017020</td>\n",
       "      <td>1.008391</td>\n",
       "      <td>1.305176</td>\n",
       "      <td>3.973564</td>\n",
       "      <td>8.839871</td>\n",
       "      <td>1.045746</td>\n",
       "      <td>4.548817</td>\n",
       "      <td>6.960762</td>\n",
       "      <td>3.758615</td>\n",
       "      <td>0.500501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.032145</td>\n",
       "      <td>-1.677119</td>\n",
       "      <td>-12.167510</td>\n",
       "      <td>-9.507402</td>\n",
       "      <td>1.220239</td>\n",
       "      <td>-5.435379</td>\n",
       "      <td>-6.699806</td>\n",
       "      <td>4.074939</td>\n",
       "      <td>-2.830792</td>\n",
       "      <td>-8.851496</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.046497</td>\n",
       "      <td>-12.128499</td>\n",
       "      <td>-9.582822</td>\n",
       "      <td>-9.367262</td>\n",
       "      <td>-10.986387</td>\n",
       "      <td>-2.595682</td>\n",
       "      <td>-9.710075</td>\n",
       "      <td>-11.325978</td>\n",
       "      <td>-9.363069</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.287295</td>\n",
       "      <td>1.450981</td>\n",
       "      <td>-9.258086</td>\n",
       "      <td>-6.608699</td>\n",
       "      <td>3.816363</td>\n",
       "      <td>-3.246286</td>\n",
       "      <td>-3.921556</td>\n",
       "      <td>6.457160</td>\n",
       "      <td>0.742799</td>\n",
       "      <td>-5.980770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346735</td>\n",
       "      <td>-9.698782</td>\n",
       "      <td>-7.330375</td>\n",
       "      <td>-6.232200</td>\n",
       "      <td>-7.569584</td>\n",
       "      <td>-0.466278</td>\n",
       "      <td>-7.291228</td>\n",
       "      <td>-9.077094</td>\n",
       "      <td>-6.421727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.212893</td>\n",
       "      <td>4.122470</td>\n",
       "      <td>-4.681202</td>\n",
       "      <td>-4.521427</td>\n",
       "      <td>6.009192</td>\n",
       "      <td>1.465326</td>\n",
       "      <td>2.119661</td>\n",
       "      <td>7.148805</td>\n",
       "      <td>2.399665</td>\n",
       "      <td>1.082333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258733</td>\n",
       "      <td>-9.066828</td>\n",
       "      <td>-6.262909</td>\n",
       "      <td>-2.188896</td>\n",
       "      <td>1.200635</td>\n",
       "      <td>0.229365</td>\n",
       "      <td>-2.450744</td>\n",
       "      <td>-1.828291</td>\n",
       "      <td>-2.160272</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.238277</td>\n",
       "      <td>6.066863</td>\n",
       "      <td>-1.901586</td>\n",
       "      <td>-2.879066</td>\n",
       "      <td>9.145269</td>\n",
       "      <td>6.819129</td>\n",
       "      <td>7.323175</td>\n",
       "      <td>7.974873</td>\n",
       "      <td>4.526339</td>\n",
       "      <td>8.480955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028362</td>\n",
       "      <td>-8.344404</td>\n",
       "      <td>-5.314031</td>\n",
       "      <td>1.427888</td>\n",
       "      <td>9.875877</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>1.569697</td>\n",
       "      <td>4.648586</td>\n",
       "      <td>0.744805</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.221614</td>\n",
       "      <td>8.464551</td>\n",
       "      <td>0.806140</td>\n",
       "      <td>-0.109049</td>\n",
       "      <td>12.327433</td>\n",
       "      <td>9.730383</td>\n",
       "      <td>9.918112</td>\n",
       "      <td>10.449979</td>\n",
       "      <td>7.032117</td>\n",
       "      <td>11.569669</td>\n",
       "      <td>...</td>\n",
       "      <td>3.600537</td>\n",
       "      <td>-4.976943</td>\n",
       "      <td>-2.583479</td>\n",
       "      <td>4.686482</td>\n",
       "      <td>12.750833</td>\n",
       "      <td>3.770563</td>\n",
       "      <td>4.717894</td>\n",
       "      <td>7.294646</td>\n",
       "      <td>3.375074</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EJWY        VALM        EGXO        HTGR        SKRF        NNSZ  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     4.237752    3.755108   -5.614445   -4.747200    6.447995    1.776850   \n",
       "std      4.121210    2.540833    3.853295    2.164355    2.796104    5.030617   \n",
       "min     -2.032145   -1.677119  -12.167510   -9.507402    1.220239   -5.435379   \n",
       "25%      0.287295    1.450981   -9.258086   -6.608699    3.816363   -3.246286   \n",
       "50%      4.212893    4.122470   -4.681202   -4.521427    6.009192    1.465326   \n",
       "75%      8.238277    6.066863   -1.901586   -2.879066    9.145269    6.819129   \n",
       "max     11.221614    8.464551    0.806140   -0.109049   12.327433    9.730383   \n",
       "\n",
       "             NYLC        GWID        TVUT        CJHI     ...            LKKS  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000     ...      500.000000   \n",
       "mean     1.718450    7.208016    2.556548    1.222064     ...        0.295252   \n",
       "std      5.771508    1.167246    2.146874    7.410762     ...        1.017020   \n",
       "min     -6.699806    4.074939   -2.830792   -8.851496     ...       -3.046497   \n",
       "25%     -3.921556    6.457160    0.742799   -5.980770     ...       -0.346735   \n",
       "50%      2.119661    7.148805    2.399665    1.082333     ...        0.258733   \n",
       "75%      7.323175    7.974873    4.526339    8.480955     ...        1.028362   \n",
       "max      9.918112   10.449979    7.032117   11.569669     ...        3.600537   \n",
       "\n",
       "             UOBF        VBHE        FRWU        NDYZ        QSBO        JDUB  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean    -9.053808   -6.291877   -2.345864    1.125596    0.284048   -2.817147   \n",
       "std      1.008391    1.305176    3.973564    8.839871    1.045746    4.548817   \n",
       "min    -12.128499   -9.582822   -9.367262  -10.986387   -2.595682   -9.710075   \n",
       "25%     -9.698782   -7.330375   -6.232200   -7.569584   -0.466278   -7.291228   \n",
       "50%     -9.066828   -6.262909   -2.188896    1.200635    0.229365   -2.450744   \n",
       "75%     -8.344404   -5.314031    1.427888    9.875877    0.983905    1.569697   \n",
       "max     -4.976943   -2.583479    4.686482   12.750833    3.770563    4.717894   \n",
       "\n",
       "             TEVK        EZTM       Label  \n",
       "count  500.000000  500.000000  500.000000  \n",
       "mean    -2.192278   -2.816977    0.500000  \n",
       "std      6.960762    3.758615    0.500501  \n",
       "min    -11.325978   -9.363069    0.000000  \n",
       "25%     -9.077094   -6.421727    0.000000  \n",
       "50%     -1.828291   -2.160272    0.500000  \n",
       "75%      4.648586    0.744805    1.000000  \n",
       "max      7.294646    3.375074    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "\n",
    "** Use scikit learn to scale the data with a MinMaxScaler. Remember not to scale the Label column, just the data. Save this scaled data as a new variable called scaled_data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = scaler.fit_transform(data.drop('Label', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>WDRT</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.473066</td>\n",
       "      <td>0.535634</td>\n",
       "      <td>0.505106</td>\n",
       "      <td>0.506493</td>\n",
       "      <td>0.470664</td>\n",
       "      <td>0.475560</td>\n",
       "      <td>0.506577</td>\n",
       "      <td>0.491460</td>\n",
       "      <td>0.546222</td>\n",
       "      <td>0.493290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566938</td>\n",
       "      <td>0.502743</td>\n",
       "      <td>0.429933</td>\n",
       "      <td>0.470179</td>\n",
       "      <td>0.499611</td>\n",
       "      <td>0.510253</td>\n",
       "      <td>0.452344</td>\n",
       "      <td>0.477748</td>\n",
       "      <td>0.490515</td>\n",
       "      <td>0.513897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.310946</td>\n",
       "      <td>0.250534</td>\n",
       "      <td>0.297009</td>\n",
       "      <td>0.230291</td>\n",
       "      <td>0.251738</td>\n",
       "      <td>0.331709</td>\n",
       "      <td>0.347306</td>\n",
       "      <td>0.183096</td>\n",
       "      <td>0.217671</td>\n",
       "      <td>0.362896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.153004</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>0.186471</td>\n",
       "      <td>0.282741</td>\n",
       "      <td>0.372406</td>\n",
       "      <td>0.164264</td>\n",
       "      <td>0.315278</td>\n",
       "      <td>0.373820</td>\n",
       "      <td>0.295068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.175002</td>\n",
       "      <td>0.308440</td>\n",
       "      <td>0.224256</td>\n",
       "      <td>0.308427</td>\n",
       "      <td>0.233734</td>\n",
       "      <td>0.144344</td>\n",
       "      <td>0.167184</td>\n",
       "      <td>0.373679</td>\n",
       "      <td>0.362326</td>\n",
       "      <td>0.140576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0.406161</td>\n",
       "      <td>0.339747</td>\n",
       "      <td>0.321808</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.143943</td>\n",
       "      <td>0.334484</td>\n",
       "      <td>0.167650</td>\n",
       "      <td>0.120774</td>\n",
       "      <td>0.230908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.471190</td>\n",
       "      <td>0.571857</td>\n",
       "      <td>0.577039</td>\n",
       "      <td>0.530516</td>\n",
       "      <td>0.431158</td>\n",
       "      <td>0.455019</td>\n",
       "      <td>0.530720</td>\n",
       "      <td>0.482172</td>\n",
       "      <td>0.530316</td>\n",
       "      <td>0.486448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562805</td>\n",
       "      <td>0.497249</td>\n",
       "      <td>0.428113</td>\n",
       "      <td>0.474318</td>\n",
       "      <td>0.510780</td>\n",
       "      <td>0.513414</td>\n",
       "      <td>0.443754</td>\n",
       "      <td>0.503143</td>\n",
       "      <td>0.510063</td>\n",
       "      <td>0.565451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.774906</td>\n",
       "      <td>0.763581</td>\n",
       "      <td>0.791290</td>\n",
       "      <td>0.705266</td>\n",
       "      <td>0.713504</td>\n",
       "      <td>0.808038</td>\n",
       "      <td>0.843847</td>\n",
       "      <td>0.611751</td>\n",
       "      <td>0.745939</td>\n",
       "      <td>0.848749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657490</td>\n",
       "      <td>0.613034</td>\n",
       "      <td>0.529129</td>\n",
       "      <td>0.609885</td>\n",
       "      <td>0.768133</td>\n",
       "      <td>0.878884</td>\n",
       "      <td>0.562276</td>\n",
       "      <td>0.781799</td>\n",
       "      <td>0.857896</td>\n",
       "      <td>0.793512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EJWY        VALM        EGXO        HTGR        SKRF        NNSZ  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.473066    0.535634    0.505106    0.506493    0.470664    0.475560   \n",
       "std      0.310946    0.250534    0.297009    0.230291    0.251738    0.331709   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.175002    0.308440    0.224256    0.308427    0.233734    0.144344   \n",
       "50%      0.471190    0.571857    0.577039    0.530516    0.431158    0.455019   \n",
       "75%      0.774906    0.763581    0.791290    0.705266    0.713504    0.808038   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             NYLC        GWID        TVUT        CJHI     ...            WDRT  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000     ...      500.000000   \n",
       "mean     0.506577    0.491460    0.546222    0.493290     ...        0.566938   \n",
       "std      0.347306    0.183096    0.217671    0.362896     ...        0.154181   \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "25%      0.167184    0.373679    0.362326    0.140576     ...        0.471542   \n",
       "50%      0.530720    0.482172    0.530316    0.486448     ...        0.562805   \n",
       "75%      0.843847    0.611751    0.745939    0.848749     ...        0.657490   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "             LKKS        UOBF        VBHE        FRWU        NDYZ        QSBO  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.502743    0.429933    0.470179    0.499611    0.510253    0.452344   \n",
       "std      0.153004    0.141003    0.186471    0.282741    0.372406    0.164264   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.406161    0.339747    0.321808    0.223077    0.143943    0.334484   \n",
       "50%      0.497249    0.428113    0.474318    0.510780    0.513414    0.443754   \n",
       "75%      0.613034    0.529129    0.609885    0.768133    0.878884    0.562276   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             JDUB        TEVK        EZTM  \n",
       "count  500.000000  500.000000  500.000000  \n",
       "mean     0.477748    0.490515    0.513897  \n",
       "std      0.315278    0.373820    0.295068  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.167650    0.120774    0.230908  \n",
       "50%      0.503143    0.510063    0.565451  \n",
       "75%      0.781799    0.857896    0.793512  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_data, columns = data.columns[:-1]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Linear Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import tensorflow and import fully_connected layers from tensorflow.contrib.layers. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\programdata\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fill out the number of inputs to fit the dimensions of the data set and set the hidden number of units to be 2. Also set the number of outputs to match the number of inputs. Also choose a learning_rate value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 30 # FILL ME IN\n",
    "num_hidden = 2 # FILL ME IN \n",
    "num_outputs = num_inputs # Must be true for an autoencoder!\n",
    "\n",
    "learning_rate = 0.01 #FILL ME IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "\n",
    "** Create a placeholder fot the data called X.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, num_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "** Create the hidden layer and the output layers using the fully_connected function. Remember that to perform PCA there is no activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer = fully_connected(inputs = X, \n",
    "                               num_outputs = num_hidden, \n",
    "                               activation_fn = None)\n",
    "outputs = fully_connected(inputs = hidden_layer, \n",
    "                         num_outputs = num_outputs, \n",
    "                         activation_fn = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "** Create a Mean Squared Error loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create an AdamOptimizer designed to minimize the previous loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train  = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init\n",
    "\n",
    "** Create an instance of a global variable intializer. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session\n",
    "\n",
    "** Now create a Tensorflow session that runs the optimizer for at least 1000 steps. (You can also use epochs if you prefer, where 1 epoch is defined by one single run through the entire dataset. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for iteration in range(num_steps):\n",
    "        sess.run(train,\n",
    "                 feed_dict = {X: X_data})\n",
    "\n",
    "    # Now ask for the hidden layer output (the 2 dimensional output)\n",
    "    output_2d = hidden_layer.eval(feed_dict = {X: X_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Confirm that your output is now 2 dimensional along the previous axis of 30 features. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now plot out the reduced dimensional representation of the data. Do you still have clear separation of classes even with the reduction in dimensions? Hint: You definitely should, the classes should still be clearly seperable, even when reduced to 2 dimensions. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21972b5def0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK6VUAdLkrpRSBej/ASE1dHzkkAZpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218ab4bd208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(output_2d[:, 0],\n",
    "            output_2d[:, 1],\n",
    "            c = data['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
